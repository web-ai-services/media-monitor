# About

Система медиа-мониторинга, покрывающая целый ряд задач:

- Парсинг ресурсов,в том числе и конфигурируемый Spider (<b>Scrapy</b>) 
- Хранение (<b>Redis, PostgreSQL, Elasticsearch</b>)
- Обработка данных (<b>PyMorphy2, NLTK, Gensim</b>) 
- Построение тематических моделей (<b>LDA, BigARTM, ETM</b>), в том числе и динамических (<b>Custom DTM, DETM</b>)
- Классификация документов по множеству критериев (<b>Personal insights, Custom Bayes Model</b>)
- Визуализация. (<b>Django, HTML+CSS+JS, Plotly, MapBox</b>)
- Автоматические формирование отчетов. (<b>LaTex</b>)

# Architecture

![architecture](https://i.ibb.co/BtRjSmy/arch.jpg)
Все компоненты системы организованы в виде Docker-контейнеров. Все контейнеры имеют доступ к одной виртуальной сети, что обеспечивает возможность обмена данными с использованием стандартных сетевых протоколов (TCP). Такая реализация обеспечивает работу подсистем в виде независимых компонентов, каждый из которых возможно заменить при необходимости.
Взаимодействие компонентов – подсистемы построения аналитики и подсистемы обработки данных – осуществляется с помощью системы хранения. Общая схема взаимодействия компонентов организована по принципу ETL (extract, transform, load): от пользователя поступает запрос на получение данных в ElasticSearch (если данные используются редко) или в Redis (если данные используются часто). Кроме того, подсистема обработки использует Airflow-scheduler, который записывает в Redis информацию о распределении задач по workers; они, в свою очередь, отчитываются в Redis о статусе выполнения своих задач. В процессе проектирования могут применяться компоненты сообразно их целевому назначению.
Визуализация структуры системы показана на рисунке 1.

Рис. 1. Структура системы
Анализ текстовых корпусов (на данном этапе – корпуса новостных сообщений в казахстанских русскоязычных интернет-СМИ объемом 1,5 млн документов с постоянным пополнением) осуществляется по загрузке workers. Новые документы загружаются в подсистему обработки данных с помощью специального парсера: на данном этапе загрузка происходит вручную по запросу пользователя, в будущем получение новых новостей будет настроено по расписанию. С заданной периодичностью будет выполняться генерация отчетов, требующих большого вычислительного времени; результаты будут размещены в хранилище - такой подход уменьшит время ожидания результатов от подсистемы обработки данных. На основе собранных данных будет выполняться дополнительное обучение модели (1–2 раза в месяц), которое будет включать в себя пересчет набора ключевых характеристик текстового корпуса. В случае, если дообучение модели не будет приводить к увеличению показателя точности (например, в задаче определения тональности текста), предусмотрено использование других ML-алгоритмов или их совокупности.
Ролевая система включает в себя следующие роли:
    1) Обычный пользователь – имеет доступ к базовой функциональности системы: поиск, фильтрация, цифровые информационные панели (так называемые дашборды).
    2) Расширенный пользователь – имеет доступ к настраиваемым отчётам, автоматическим оповещениям о «горячих темах», возможность проводить фильтрацию по именованным сущностям (например, человек, организация, регион) в статьях. Такое разделение пользователей обусловлено последующим использованием системы государственными органами.
    3) Разработчик – имеет доступ к панели администратора Airflow и к репозиторию, в котором хранятся Airflow DAG. Может добавлять и менять свои задачи, запускать и отслеживать их выполнение.
    4) Администратор – супер-пользователь, имеет полный набор прав по работе с системой.
Распределение доступной функциональности по ролям представлена на рис. 2.

Рис. 2. Распределение доступа к системе по ролям
В следующих подразделах более подробно описаны выбранный инструментарий для каждой из перечисленных подсистем.
2.1 Подсистема обработки данных
В ходе анализа для удовлетворения всех этих потребностей была выбрана программная платформа с открытым исходным кодом Apache Airflow [24]. Основные компоненты данной платформы:
    1. Airflow-worker – основной компонент, выполняющий обработку данных. Может быть горизонтально масштабирован, в том числе на отдельные сервера/облачные VM. В текущем варианте архитектуры в образ контейнера Airflow-worker заранее встраиваются необходимые зависимости, однако принципиально процесс инъекции зависимостей может происходить различным образом, в том числе, путём динамичного получения Docker-контейнеров из публичных, либо приватных репозиториев.
    2. Airflow-scheduler – компонент, отвечающий за назначение задач Airflow-workerам в порядке, определённом Airflow DAG-ами. Airflow DAG – нецикличный направленный граф, описывающий порядок выполнения определённых задач, а также содержащий информацию о расписании, приоритетах, поведении в случае исключений и пр.
    3. Airflow web server – веб-интерфейс, позволяющий отслеживать и контролировать ход выполнения задач.
Алгоритмы машинного обучения реализованы в системе как отдельные Airflow-задачи.
2.2 Хранилище
В системе предусмотрено три вида хранилищ:
    1) PostgreSQL – выполняет роль персистентного хранилища для структурированных данных. Его использование обусловлено широкими возможностями данной реляционной БД (среди свободно распространяемых продуктов), взаимодействия с широким кругом инструментов. Основные типы данных, хранящиеся в этой базе:
        a) новости и метаданные,
        b) обработанные данные на уровне разных базовых единиц анализа (токен/слово/фраза/предложение/текст), в том числе векторизации, результаты лемматизации, очистки и пр.
        c) результаты проведения тематического моделирования,
        d) результаты классификации новостей по различным признакам (тональность, политизированность, социальная значимость и пр.)
    2) ElasticSearch – in-memory NoSQL хранилище, предназначенное для хранения неструктурированных или слабоструктурированных данных, а также быстрого поиска (в том числе полнотекстового), фильтрации и потокового доступа. В сравнении с другими NoSQL базами для хранения документов с произвольной структурой, такими как MongoDB и CouchDB, ElasticSearch выделяется расширенными инструментами для индексирования текста, позволяющими проводить полнотекстовый поиск по большим объёмам документов практически в реальном времени. Также в виду возможности построения продвинутых индексов для данных, возможно выполнение сложных агрегаций в самой базе, в том числе распределенно. ElasticSearch выполняет несколько функций:
        a) основное хранилище для доступа, поиска и фильтрации данных конечным пользователем,
        b) основное хранилище для ETL (Extract-Transform-Load) процессов обработки данных – в том числе запись любых промежуточных результатов в свободной форме,
        c) хранилище для кэширования определённых результатов вычислений, необходимых для построения дашбордов и отчётов в системе,
        d) ElasticSearch дублирует данные, хранящиеся в PostgreSQL как персистентном хранилище, поскольку ElasticSearch является in-memory базой данных без гарантий относительно персистентности и целостности данных.
    3) Redis – быстрое key-value хранилище, используемое для кэширования отдельных страниц и элементов, а также для кэширования сессий авторизации. В Redis хранятся служебные данные, а также кэш страниц и элементов, к которым происходит частый доступ.
Все три основных хранилища системы могут быть легко масштабированы на несколько отдельных компьтеров, поддерживается как горизонтальное масштабирование, так и репликация, при этом ElasticSearch и Redis показывают близкое к линейному увеличение производительности при горизонтальном масштабировании.
Для хранения служебных данных, таких как состояния выполнения задач, используется отдельный кластер PostgreSQL. Для запуска и отслеживания прогресса задач используется связка Celery+Redis.
2.3 Подсистема построения аналитических отчетов
Интерфейс подсистемы представляет их себя HTML+CSS+JS веб-сайт с доступом по протоколу HTTP. HTML+CSS+JS – выбор этого стека технологий для интерфейса оправдан тем фактом, что именно веб-интерфейсы являются наиболее распространённой и повсеместно поддерживаемой технологией построение UI с возможностью доступа с любых устройств, операционных систем из любой точки мира, при условии наличия веб-браузера и подключения к сети Интернет.
Веб-приложение реализовано на Python фреймворке Django, в качестве веб-сервера выступает Gunicorn, реверс-прокси Nginx. Веб-приложение имеет доступ как к персистентному хранилищу PostgreSQL, так и к ElasticSearch. В Django есть встроенный Cache Framework, который позволяет кэшировать страницы и элементы страниц в Redis. Например, если предполагается, что на страницу будут заходить часто, а считается она долго (например, 3 секунды), то лучше такую страницу кешировать в Redis, что позволит ускорить доступ к необходимым данным.
Фреймворк Django был выбран из трех основных соображений:
    1. Возможность быстрой Agile-разработки веб-интерфейса и модели хранения данных. Скорость разработки на фреймворки Django значительно выше, чем при использовании таких аналогов, как Spring (Java), Yii (PHP) и Node.js (JavaScript). 
    2. В виду того, что проект предполагает проведение анализа данных и построение моделей машинного обучения, в том числе NLP, язык Python является оптимальным выбором, так как большая часть State-of-the-art моделей и методов ML/AI и NLP разрабатывается сообществом именно на языке Python. 
    3. Django ORM лучше работает с БД PostgreSQL.
Веб-приложение реализует ряд страниц для фильтрации, поиска, доступа к различным дашбордам и отчётам. На первом этапе реализации системы дашборды считаются заранее вручную. При дальнейшем развитии системы будет использоваться фасетный поиск (Faceted Search) из Elastic Search. Для отрисовки графиков будет использоваться Python-библиотека визуализации данных Plotly.
Пример того, какую информацию могут отображать графики:
    1. Динамику по тональности (+манипулятивность, политизированность и пр.), тематикам, количеству. просмотров/комментариев с фильтрацией по СМИ, тематикам, авторам, тегам + полнотекстовый поиск.
    2. Распределение тематик, значений тональности и пр. в статике, с фильтрациями и поиском.
    3. Выявление выбросов/аномалий для аналитических отчётов (самые “горячие” темы и пр.).
    
# Perspectives
Возможные варианты переосмысления, имеющейся реализации [Media Analytics](https://nlp.iict.kz/):
1. Аналог [ALEM MEDIA MONITORING](https://alem.kz/product-1/), сервиса, направленного на:

    > Полный контроль информационного поля, включая СМИ (Интернет, телевидение, радио, газеты) и социальные медиа

    > Управление репутацией, контроль имиджа, повышение эффективности связи с общественностью

    > Принятие правильных управленческих решений, основанных на достоверных фактах

    > Гибкая конфигурация отчетов и аналитических записок
    
    ___
    ##### Вкратце
    Обработка входящего NER реквеста с формированием отчета об освещаемости входящей сущности, тональной окраске. Составление KPI рекламных компаний, регулирование PR отделов, сравнение с конкурентами итд.

2. Сервис по поиску наиболее релевантного в плане интеграции, инфлюэнсера (блогера) из пространства: YouTube, Instagram, Facebook, итд. Ближайший похожий сервис это [GetBlogger](https://getblogger.ru/). Пайплайн примерно следующий:

    1) Парсинг соц-сетей, формирование корпуса с привязкой непосредственно к блогеру
    2) Тематическая модель корпуса, представление его в пространстве "контенто-тем". Тем самым мы через топик-эмбеддинг, определяем причастность непосредственно блогера к "контенто-теме"
    3) Модель, которая будет получать признаковое описание бизнеса, и выдавать наиболее релевантную "контенто-тему".
