# About

Система медиа-мониторинга, покрывающая целый ряд задач:

- Парсинг ресурсов,в том числе и конфигурируемый Spider (<b>Scrapy</b>) 
- Хранение (<b>Redis, PostgreSQL, Elasticsearch</b>)
- Обработка данных (<b>PyMorphy2, NLTK, Gensim</b>) 
- Построение тематических моделей (<b>LDA, BigARTM, ETM</b>), в том числе и динамических (<b>Custom DTM, DETM</b>)
- Классификация документов по множеству критериев (<b>Personal insights, Custom Bayes Model</b>)
- Визуализация. (<b>Django, HTML+CSS+JS, Plotly, MapBox</b>)
- Автоматические формирование отчетов. (<b>LaTex</b>)

# Architecture

![architecture](https://i.ibb.co/BtRjSmy/arch.jpg)

Все компоненты системы организованы в виде Docker-контейнеров. Такая реализация обеспечивает работу подсистем в виде независимых компонентов, каждый из которых возможно заменить при необходимости.

1. Анализ текстовых корпусов (на данном этапе – корпуса новостных сообщений в казахстанских русскоязычных интернет-СМИ объемом 1,5 млн документов с постоянным пополнением) осуществляется по загрузке workers. Новые документы загружаются в подсистему обработки данных с помощью специального парсера: на данном этапе загрузка происходит вручную по запросу пользователя, в будущем получение новых новостей будет настроено по расписанию. С заданной периодичностью будет выполняться генерация отчетов, требующих большого вычислительного времени; результаты будут размещены в хранилище - такой подход уменьшит время ожидания результатов от подсистемы обработки данных. На основе собранных данных будет выполняться дополнительное обучение модели (1–2 раза в месяц), которое будет включать в себя пересчет набора ключевых характеристик текстового корпуса. В случае, если дообучение модели не будет приводить к увеличению показателя точности (например, в задаче определения тональности текста), предусмотрено использование других ML-алгоритмов или их совокупности.

В ходе анализа для удовлетворения всех этих потребностей была выбрана программная платформа с открытым исходным кодом Apache Airflow. Основные компоненты данной платформы:
    1. Airflow-worker – основной компонент, выполняющий обработку данных. Может быть горизонтально масштабирован, в том числе на отдельные сервера/облачные VM. В текущем варианте архитектуры в образ контейнера Airflow-worker заранее встраиваются необходимые зависимости, однако принципиально процесс инъекции зависимостей может происходить различным образом, в том числе, путём динамичного получения Docker-контейнеров из публичных, либо приватных репозиториев.
    2. Airflow-scheduler – компонент, отвечающий за назначение задач Airflow-workerам в порядке, определённом Airflow DAG-ами. Airflow DAG – нецикличный направленный граф, описывающий порядок выполнения определённых задач, а также содержащий информацию о расписании, приоритетах, поведении в случае исключений и пр.
    3. Airflow web server – веб-интерфейс, позволяющий отслеживать и контролировать ход выполнения задач.
Алгоритмы машинного обучения реализованы в системе как отдельные Airflow-задачи.

2. Подсистема построения аналитических отчетов
Интерфейс подсистемы представляет их себя HTML+CSS+JS веб-сайт с доступом по протоколу HTTP. HTML+CSS+JS – выбор этого стека технологий для интерфейса оправдан тем фактом, что именно веб-интерфейсы являются наиболее распространённой и повсеместно поддерживаемой технологией построение UI с возможностью доступа с любых устройств, операционных систем из любой точки мира, при условии наличия веб-браузера и подключения к сети Интернет.
Веб-приложение реализовано на Python фреймворке Django, в качестве веб-сервера выступает Gunicorn, реверс-прокси Nginx. Веб-приложение имеет доступ как к персистентному хранилищу PostgreSQL, так и к ElasticSearch. В Django есть встроенный Cache Framework, который позволяет кэшировать страницы и элементы страниц в Redis. Например, если предполагается, что на страницу будут заходить часто, а считается она долго (например, 3 секунды), то лучше такую страницу кешировать в Redis, что позволит ускорить доступ к необходимым данным.
Фреймворк Django был выбран из трех основных соображений:
    1. Возможность быстрой Agile-разработки веб-интерфейса и модели хранения данных. Скорость разработки на фреймворки Django значительно выше, чем при использовании таких аналогов, как Spring (Java), Yii (PHP) и Node.js (JavaScript). 
    2. В виду того, что проект предполагает проведение анализа данных и построение моделей машинного обучения, в том числе NLP, язык Python является оптимальным выбором, так как большая часть State-of-the-art моделей и методов ML/AI и NLP разрабатывается сообществом именно на языке Python. 
    3. Django ORM лучше работает с БД PostgreSQL.
Веб-приложение реализует ряд страниц для фильтрации, поиска, доступа к различным дашбордам и отчётам. На первом этапе реализации системы дашборды считаются заранее вручную. При дальнейшем развитии системы будет использоваться фасетный поиск (Faceted Search) из Elastic Search. Для отрисовки графиков будет использоваться Python-библиотека визуализации данных Plotly.

3. Пример того, какую информацию могут отображать графики:
    1. Динамику по тональности (+манипулятивность, политизированность и пр.), тематикам, количеству. просмотров/комментариев с фильтрацией по СМИ, тематикам, авторам, тегам + полнотекстовый поиск.
    2. Распределение тематик, значений тональности и пр. в статике, с фильтрациями и поиском.
    3. Выявление выбросов/аномалий для аналитических отчётов (самые “горячие” темы и пр.).
    
# Perspectives
Возможные варианты переосмысления, имеющейся реализации [Media Analytics](https://nlp.iict.kz/):
1. Аналог [ALEM MEDIA MONITORING](https://alem.kz/product-1/), сервиса, направленного на:

    > Полный контроль информационного поля, включая СМИ (Интернет, телевидение, радио, газеты) и социальные медиа

    > Управление репутацией, контроль имиджа, повышение эффективности связи с общественностью

    > Принятие правильных управленческих решений, основанных на достоверных фактах

    > Гибкая конфигурация отчетов и аналитических записок
    
    ___
    ##### Вкратце
    Обработка входящего NER реквеста с формированием отчета об освещаемости входящей сущности, тональной окраске. Составление KPI рекламных компаний, регулирование PR отделов, сравнение с конкурентами итд.

2. Сервис по поиску наиболее релевантного в плане интеграции, инфлюэнсера (блогера) из пространства: YouTube, Instagram, Facebook, итд. Ближайший похожий сервис это [GetBlogger](https://getblogger.ru/). Пайплайн примерно следующий:

    1) Парсинг соц-сетей, формирование корпуса с привязкой непосредственно к блогеру
    2) Тематическая модель корпуса, представление его в пространстве "контенто-тем". Тем самым мы через топик-эмбеддинг, определяем причастность непосредственно блогера к "контенто-теме"
    3) Модель, которая будет получать признаковое описание бизнеса, и выдавать наиболее релевантную "контенто-тему".
